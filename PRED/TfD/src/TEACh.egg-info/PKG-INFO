Metadata-Version: 2.1
Name: TEACh
Version: 1.0
Summary: Task-driven Embodied Agents that Chat
Home-page: https://github.com/alexa/TEACh
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown

# FILM for TEACh
[Don't Copy the Teacher: Data and Model Challenges in Embodied Dialogue](https://arxiv.org/abs/2210.04443)

So Yeon Min, Hao Zhu, Ruslan Salakhutdinov, Yonatan Bisk

You **cannot** run ET or other models with this code.

## Downloading the dataset
Download as in the original [teach repo](https://github.com/alexa/teach#downloading-the-dataset)

This is where I saved it.

![Screen Shot 2023-04-04 at 3 39 42 PM](https://user-images.githubusercontent.com/77866067/229901724-33443e6a-ebfb-4f36-a20a-021e7cb5d1b0.png)

## Setting up this repository


#### Step 1 - git clone this repo
#### Step 2 - Copy files from google drive 
Download and unzip from this link: https://drive.google.com/file/d/1UOBNhuaKRcG3HxT14aRM_Fud5YH5tVCo/view?usp=share_link

- Move "BERT_models" inside "FILM_model/models/instructions_processed_LP"
- Move "depth_models" inside "FILM_model/models/depth/depth_models"
- Move "maskrcnn_alfworld" inside " FILM_model/models/segmentation" 

#### Step 3 - Docker pull
```
docker pull symin95/teach_without_api:latest
```
https://hub.docker.com/repository/docker/symin95/teach_without_api/general

#### Step 4 - Modify the "volume" lines in "docker_run_3.8.py"
![Screen Shot 2023-04-04 at 3 41 02 PM](https://user-images.githubusercontent.com/77866067/229902024-fdba0325-4e7a-4a83-9454-77e2304ea2f2.png)

Modify these lines so that they contain the directory of this repo and the teach data repo

#### Step 5 - Run docker, turn on xserver, etc
```
python docker_run_3.8.py --headless -i 79593680304a -c c01 #Run docker
cd /home/soyeonm/TEACH_FILM_for_jhc #go to the directory of this repo inside docker
TMUX=tmux #Open tmux and turn on xserver
tmux
Xorg -noreset +extension GLX +extension RANDR +extension RENDER :0
#Get out of tmux
export DISPLAY=:0
```
#### Step 6 - Extra installations
```
pip install transformers==4.9.2 && pip install -e . && pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html && python -m pip install -U detectron2 -f \
  https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.8/index.html
```

#### Step 6 - Run command 
Set the variables as in the original [teach repo](https://github.com/soyeonm/TEACH_FILM_for_jhc#evaluation)
```
export DATA_DIR=/home/soyeonm/TEACH_DATA
export OUTPUT_DIR=/home/soyeonm/TEACH_FILM_for_jhc/output
export IMAGE_DIR=/home/soyeonm/TEACH_FILM_for_jhc/img_dir
export METRICS_FILE=/home/soyeonm/TEACH_FILM_for_jhc/output/metics
```

Run command 

```
python FILM_model/pre_download_bert.py
```
```
CUDA_VISIBLE_DEVICES=0 python src/teach/cli/inference.py --data_dir $DATA_DIR   --output_dir $OUTPUT_DIR   --split valid_seen  --metrics_file $METRICS_FILE  --model_module teach.inference.FILM_teach_model --model_class FILMModel  --images_dir $IMAGE_DIR --set_dn  edh_vs_0_304 --map_pred_threshold 40 --max_episode_length 500 --cat_pred_threshold 10  --use_bert --start_idx 0 --end_idx 304
```
"FILM_model/pre_download_bert.py" download bert configs and model weights (you only need to do it once).

#### Step 7 - Check results 

Check results in "results/analyze_recs". Pickles are generated for each command. 

Calculate success rate:
![Screen Shot 2023-04-04 at 3 57 10 PM](https://user-images.githubusercontent.com/77866067/229905790-dc4b2b11-48bf-4478-8bbc-035cfe5f38e1.png)


## More explanations about the commands
This code can run both "edh" and "tfd" tasks.
Default is EDH. To run TfD, put a "--tfd" flag. 

#### EDH
Example EDH Command:

```
CUDA_VISIBLE_DEVICES=0 python src/teach/cli/inference.py --data_dir $DATA_DIR   --output_dir $OUTPUT_DIR   --split valid_seen  --metrics_file $METRICS_FILE  --model_module teach.inference.FILM_teach_model --model_class FILMModel  --images_dir $IMAGE_DIR --set_dn  may24_edh_vs_0_304 --map_pred_threshold 40 --max_episode_length 500 --cat_pred_threshold 10  --use_bert --start_idx 0 --end_idx 304
```

Flags:
- set_dn: The name of the saved pickle (in results/analysis_recs)
- start_idx: start of the task index
- end_idx: end of the task index

#### TfD
Example TfD Command:

```
CUDA_VISIBLE_DEVICES=0 python src/teach/cli/inference.py --data_dir $DATA_DIR   --output_dir $OUTPUT_DIR   --split valid_unseen  --metrics_file $METRICS_FILE  --model_module teach.inference.FILM_teach_model --model_class FILMModel  --images_dir $IMAGE_DIR --set_dn tfd_vus_0_77 --map_pred_threshold 40 --max_episode_length 500 --cat_pred_threshold 10 --tfd --use_bert --start_idx 0 --end_idx 77
```
Default is EDH. To run TfD, put a "--tfd" flag. 


## License

The code is licensed under the MIT License (see SOFTWARELICENSE), images are licensed under Apache 2.0 
(see IMAGESLICENSE) and other data files are licensed under CDLA-Sharing 1.0 (see DATALICENSE).

